{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad96800d-eacf-474c-8e94-4b239266e963",
   "metadata": {},
   "source": [
    "# Prompt Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986db25-00c0-4496-ba3d-1827c5ae3bc5",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12069b71-c878-4199-8d7b-0ba469294742",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7c6f4-67c2-4b9c-838f-4ae4c8c48b70",
   "metadata": {},
   "source": [
    "If you would like to view the utils.py file, uncomment the following line and run it. Alternately to view it in an editor, click `file->open` and look for utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a2aac-8aba-42c2-b98a-6260e9c866df",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!cat utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c8b00-1f82-4ae8-973d-6775e8d1c14f",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3131d-c1e0-4ce9-909b-222063cab03d",
   "metadata": {
    "id": "DC3VBQGs7ggW"
   },
   "source": [
    "## Using the \"user\" and \"assistant\" roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a39424b-ddc4-4a99-969d-270a06adf472",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Who wrote the book Charlotte's Web?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "question = \"Who wrote the book Charlotte's Web?\"\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    f\"{question}\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfba2fe-8fa3-41b4-b91c-2f66dc6bfe5f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "from  utils import llama31\n",
    "response = llama31(prompt,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7ffce6-514a-4e4a-acdf-ca65e49d2627",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"id\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"8cf5a7eedf54fa4a-SJC\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"object\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"text.completion\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"created\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1728385528\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"model\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"prompt\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"choices\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"text\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\\n\\nThe book \\\"Charlotte's Web\\\" was written by E.B. White.\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"finish_reason\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"eos\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"seed\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m557474721029899970\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"logprobs\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mnull\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"index\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"usage\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"prompt_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m17\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"completion_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m17\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"total_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m34\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import cprint\n",
    "response = llama31(prompt,8, raw=True)\n",
    "\n",
    "cprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8160c83-47d3-42b5-92fb-86f5fd97af51",
   "metadata": {},
   "source": [
    "# Multi-turn chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c191c7-e158-4865-a80d-fade3d145d58",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "follow_up_question = \"Three best quotes in it\"\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past  \n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # new\n",
    "    f\"{follow_up_question}\"                          # new\n",
    "    \"<|eot_id|>\"                                     # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  # new\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e798493a-e9c8-4d96-8baf-f18c8bc8d2c6",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three of the most famous quotes from \"Charlotte's Web\" by E.B. White:\n",
      "\n",
      "1. **\"Alone we can do so little; together we can do so much.\"** - This quote is a reflection on the power of friendship and teamwork, as embodied by the relationship between Charlotte and Wilbur.\n",
      "2. **\"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"** - This quote highlights the special bond between Charlotte and Wilbur, and the unique qualities that make Charlotte a true friend.\n",
      "3. **\"Where there is great love, there are always miracles.\"** - This quote captures the magical and heartwarming spirit of the story, and the idea that love and kindness can lead to extraordinary events and outcomes.\n",
      "\n",
      "These quotes capture the essence of the story and its themes of friendship, loyalty, and the power of love and kindness.\n"
     ]
    }
   ],
   "source": [
    "follow_up_response = llama31(follow_up_prompt)\n",
    "print(follow_up_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb293be0-612e-48df-b74a-d4d2d98ca8b2",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three of the most famous quotes from \"Charlotte's Web\" by E.B. White:\n",
       "\n",
       "1. **\"Alone we can do so little; together we can do so much.\"** - This quote is a reflection on the power of friendship and teamwork, as embodied by the relationship between Charlotte and Wilbur.\n",
       "2. **\"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"** - This quote highlights the special bond between Charlotte and Wilbur, and the unique qualities that make Charlotte a true friend.\n",
       "3. **\"Where there is great love, there are always miracles.\"** - This quote captures the magical and heartwarming spirit of the story, and the idea that love and kindness can lead to extraordinary events and outcomes.\n",
       "\n",
       "These quotes capture the essence of the story and its themes of friendship, loyalty, and the power of love and kindness."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(follow_up_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6036cfb-876b-4487-8325-33f03b4ff085",
   "metadata": {},
   "source": [
    "#### Without message history\n",
    "This is not in the video, but you can try the same prompt *Without* including history and see the models responds with three quotes - but not from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899eba88-632f-4ff9-bae6-8a5831284bfa",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Here are three best quotes:\n",
       "\n",
       "1. **\"Believe you can and you're halfway there.\"** - Theodore Roosevelt\n",
       "\n",
       "This quote emphasizes the importance of having a positive mindset and believing in oneself. It suggests that having confidence and faith in one's abilities can lead to success.\n",
       "\n",
       "2. **\"The only way to do great work is to love what you do.\"** - Steve Jobs\n",
       "\n",
       "This quote highlights the significance of passion and enjoyment in one's work. It suggests that when we love what we do, we are more likely to be motivated, inspired, and produce high-quality work.\n",
       "\n",
       "3. **\"Success is not final, failure is not fatal: It is the courage to continue that counts.\"** - Winston Churchill\n",
       "\n",
       "This quote emphasizes the importance of perseverance and resilience in the face of challenges. It suggests that success is not a permanent state, and that failure is not a defining moment, but rather it's the courage to keep going that truly matters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Three Best quotes\"\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"  \n",
    "    \"<|start_header_id|>user<|end_header_id|>\"\n",
    "    f\"{question}\"\n",
    "    \"<|eot_id|>\"\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "response = llama31(prompt,8)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0f383-4115-44d5-9a58-62463ec5cbfb",
   "metadata": {},
   "source": [
    "## Using \"system\" role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed0d3ce-a42b-446b-8a88-a4cefb185acc",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "* \"Champions are made from something they have deep inside them - a desire, a dream, a vision.\" - Muhammad Ali\n",
       "* \"It's not whether you get knocked down, it's whether you get up.\" - Vince Lombardi\n",
       "* \"Hard work, dedication, and a willingness to learn are the keys to success in any field, including sports.\" - Michael Jordan"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Three Great quotes\"\n",
    "system_message = (\n",
    "    \"You are an expert in quotes about sports \" \n",
    "    \"You provide just the quotes and no commentary. \"\n",
    "    \"Reply in markdown\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"\n",
    "    \"<|start_header_id|>system<|end_header_id|>\"\n",
    "    f\"{system_message}\"\n",
    "    \"<|eot_id|>\"    \n",
    "    \"<|start_header_id|>user<|end_header_id|>\"\n",
    "    f\"{question}\"\n",
    "    \"<|eot_id|>\"\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "response = llama31(prompt,70)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5c210f-080b-4fe1-8a7b-7ff38d0ae9c8",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "* \"The only way to get started is to quit talking and begin doing.\" - John Wooden\n",
       "* \"It's not about being the best, it's about being better than you were yesterday.\" - Bo Jackson\n",
       "* \"Success is not final, failure is not fatal: It is the courage to continue that counts.\" - Winston Churchill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "follow_up_question = \"three more\"\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"\n",
    "    \"<|start_header_id|>system<|end_header_id|>\"      # system\n",
    "    f\"{system_message}\"                               # system\n",
    "    \"<|eot_id|>\"                                      # system\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past\n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"         # new\n",
    "    f\"{follow_up_question}\"                            # new     \n",
    "    \"<|eot_id|>\"                                       # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"    # new\n",
    ")\n",
    "response = llama31(follow_up_prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ecab0-a233-414e-a62d-dfb7b6bfbeef",
   "metadata": {},
   "source": [
    "# Chat with Llama using higher-level message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67920bea-5b75-4a42-a3a0-0aae77bc0842",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    \"Who wrote the book Charlotte's Web?\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "response = llama31(prompt,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58aa6676-3f4b-4d26-b679-ce392ec73845",
   "metadata": {
    "height": 149,
    "id": "nw9GEik8PWrx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Who wrote the book Charlotte's Web?\"\n",
    "    }\n",
    "  ]\n",
    "response = llama31(messages,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d3c1da-383e-423c-a1e8-d2c355febde0",
   "metadata": {
    "height": 404
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three notable quotes from \"Charlotte's Web\":\n",
      "\n",
      "1. \"Alone, no philosopher is grander than a pig, alone, no poet more subtle than a pig, alone, no more beautiful than a pig.\"\n",
      "2. \"You have been my friend. That in itself is a tremendous thing. You have no idea what a difference it makes to the quality of one's life, the difference it makes for me.\"\n",
      "3. \"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\n"
     ]
    }
   ],
   "source": [
    "follow_up_question = \"Three Best quotes\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are an terse expert in children's literature\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Who wrote the book Charlotte's Web?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": response\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": follow_up_question\n",
    "    }\n",
    "  ]\n",
    "\n",
    "response = llama31(messages,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b98689-fa40-4466-86f7-4ac17e206d81",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    def generate(self, user_question, model=8, temp=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\":user_question})\n",
    "        response = llama31(self.messages, model, temperature=temp)\n",
    "        self.messages.append({\"role\":\"assistant\", \"content\":response})\n",
    "        return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7479e19b-8270-4368-9bd9-cdeed5ed5664",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.B. White wrote the book \"Charlotte\\'s Web\".'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a terse expert in Childrens literature.\" \n",
    "conv = Conversation(system_message)\n",
    "conv.generate(\"Who wrote the book Charlotte's Web?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da3f5c43-262a-4b40-b00f-e6af7269e3eb",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three quotes from \"Charlotte's Web\":\n",
       "\n",
       "1. \"Wherever you go, go with all your heart.\"\n",
       "2. \"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\n",
       "3. \"Alone, no philosopher is grander than a pig, alone.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = conv.generate(\"What are three quotes\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be4e57bc-f77d-40f2-9b92-36c4dd8f8756",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a terse expert in Childrens literature.'},\n",
       " {'role': 'user', 'content': \"Who wrote the book Charlotte's Web?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'E.B. White wrote the book \"Charlotte\\'s Web\".'},\n",
       " {'role': 'user', 'content': 'What are three quotes'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Here are three quotes from \"Charlotte\\'s Web\":\\n\\n1. \"Wherever you go, go with all your heart.\"\\n2. \"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\\n3. \"Alone, no philosopher is grander than a pig, alone.\"'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d68ae5-31e7-4ebc-9100-88be9470ee45",
   "metadata": {
    "id": "5QntbEMl9uO5"
   },
   "source": [
    "## Multi-lingual Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4842cb63-d0b6-487c-b9ed-38f6e86b7ea0",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are 3 advanced phrases in each of the 8 languages:\n",
       "\n",
       "**English**\n",
       "\n",
       "1. \"The nuances of her argument were lost on me.\"\n",
       "   (Meaning: I didn't understand the subtleties of her argument.)\n",
       "\n",
       "2. \"The new policy has been met with widespread skepticism.\"\n",
       "   (Meaning: Many people are doubtful about the new policy.)\n",
       "\n",
       "3. \"Her diplomatic efforts were instrumental in brokering a peace treaty.\"\n",
       "   (Meaning: Her diplomatic actions were crucial in creating a peace agreement.)\n",
       "\n",
       "**German**\n",
       "\n",
       "1. \"Die Nuancen ihrer Argumentation waren mir entgangen.\"\n",
       "   (Meaning: Ich habe die Feinheiten ihrer Argumentation nicht verstanden.)\n",
       "\n",
       "2. \"Die neue Politik wurde von weit verbreiteter Skepsis aufgenommen.\"\n",
       "   (Meaning: Viele Menschen sind skeptisch gegen√ºber der neuen Politik.)\n",
       "\n",
       "3. \"Ihre diplomatischen Bem√ºhungen waren entscheidend f√ºr den Abschluss eines Friedensvertrags.\"\n",
       "   (Meaning: Ihre diplomatischen Aktionen waren entscheidend f√ºr den Abschluss eines Friedensvertrags.)\n",
       "\n",
       "**French**\n",
       "\n",
       "1. \"Les nuances de son argumentation m'√©taient √©chapp√©es.\"\n",
       "   (Meaning: Je n'ai pas compris les subtilit√©s de son argumentation.)\n",
       "\n",
       "2. \"La nouvelle politique a √©t√© accueillie avec scepticisme g√©n√©ralis√©.\"\n",
       "   (Meaning: Beaucoup de gens sont dubitatifs √† l'√©gard de la nouvelle politique.)\n",
       "\n",
       "3. \"Ses efforts diplomatiques ont √©t√© d√©cisifs pour n√©gocier un trait√© de paix.\"\n",
       "   (Meaning: Ses actions diplomatiques ont √©t√© cruciales pour n√©gocier un trait√© de paix.)\n",
       "\n",
       "**Italian**\n",
       "\n",
       "1. \"Le sfumature del suo argomento mi sono sfuggite.\"\n",
       "   (Meaning: Non ho capito le sfumature del suo argomento.)\n",
       "\n",
       "2. \"La nuova politica √® stata accolta con diffidenza generalizzata.\"\n",
       "   (Meaning: Molti sono diffidenti riguardo alla nuova politica.)\n",
       "\n",
       "3. \"I suoi sforzi diplomatici sono stati decisivi per negoziare un trattato di pace.\"\n",
       "   (Meaning: Le sue azioni diplomatiche sono state cruciali per negoziare un trattato di pace.)\n",
       "\n",
       "**Portuguese**\n",
       "\n",
       "1. \"As nuances do seu argumento me escaparam.\"\n",
       "   (Meaning: Eu n√£o entendi as nuances do seu argumento.)\n",
       "\n",
       "2. \"A nova pol√≠tica foi recebida com ceticismo generalizado.\"\n",
       "   (Meaning: Muitas pessoas s√£o c√©ticas em rela√ß√£o √† nova pol√≠tica.)\n",
       "\n",
       "3. \"Seus esfor√ßos diplom√°ticos foram decisivos para negociar um tratado de paz.\"\n",
       "   (Meaning: Suas a√ß√µes diplom√°ticas foram cruciais para negociar um tratado de paz.)\n",
       "\n",
       "**Hindi**\n",
       "\n",
       "1. \"‡§â‡§∏‡§ï‡•á ‡§§‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§∏‡•Ç‡§ï‡•ç‡§∑‡•ç‡§Æ‡§§‡§æ‡§è‡§Å ‡§Æ‡•Å‡§ù‡•á ‡§∏‡§Æ‡§ù ‡§Æ‡•á‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§à‡§Ç‡•§\"\n",
       "   (Meaning: ‡§Æ‡•à‡§Ç ‡§â‡§∏‡§ï‡•á ‡§§‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§∏‡•Ç‡§ï‡•ç‡§∑‡•ç‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§™‡§æ‡§Ø‡§æ‡•§)\n",
       "\n",
       "2. \"‡§®‡§à ‡§®‡•Ä‡§§‡§ø ‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡§Ç‡§¶‡•á‡§π ‡§ï‡§æ ‡§∏‡§æ‡§Æ‡§®‡§æ ‡§ï‡§∞‡§®‡§æ ‡§™‡§°‡§º‡§æ‡•§\"\n",
       "   (Meaning: ‡§¨‡§π‡•Å‡§§ ‡§∏‡•á ‡§≤‡•ã‡§ó ‡§®‡§à ‡§®‡•Ä‡§§‡§ø ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø ‡§∏‡§Ç‡§¶‡•á‡§π‡•Ä ‡§π‡•à‡§Ç‡•§)\n",
       "\n",
       "3. \"‡§â‡§∏‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§®‡•Ä‡§§‡§ø ‡§ï‡•á ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§•‡•á ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∂‡§æ‡§Ç‡§§‡§ø ‡§∏‡§Ç‡§ß‡§ø ‡§π‡•ã ‡§∏‡§ï‡•Ä‡•§\"\n",
       "   (Meaning: ‡§â‡§∏‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§®‡•Ä‡§§‡§ø ‡§ï‡•á ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§•‡•á ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∂‡§æ‡§Ç‡§§‡§ø ‡§∏‡§Ç‡§ß‡§ø ‡§π‡•ã ‡§∏‡§ï‡•Ä‡•§)\n",
       "\n",
       "**Spanish**\n",
       "\n",
       "1. \"Las sutilezas de su argumento me pasaron desapercibidas.\"\n",
       "   (Meaning: No entend√≠ las sutilezas de su argumento.)\n",
       "\n",
       "2. \"La nueva pol√≠tica ha sido recibida con escepticismo generalizado.\"\n",
       "   (Meaning: Muchas personas son esc√©pticas en relaci√≥n con la nueva pol√≠tica.)\n",
       "\n",
       "3. \"Sus esfuerzos diplom√°ticos fueron decisivos para negociar un tratado de paz.\"\n",
       "   (Meaning: Sus acciones diplom√°ticas fueron cruciales para negociar un tratado de paz.)\n",
       "\n",
       "**Thai**\n",
       "\n",
       "1. \"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏ò‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ\"\n",
       "   (Meaning: ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏ò‡∏≠)\n",
       "\n",
       "2. \"‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡∏á\"\n",
       "   (Meaning: ‡∏°‡∏µ‡∏Ñ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÉ‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà)\n",
       "\n",
       "3. \"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏π‡∏ï‡∏Ç‡∏≠‡∏á‡πÄ‡∏ò‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏£‡∏à‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏™‡∏±‡∏ô‡∏ï‡∏¥‡∏†‡∏≤‡∏û\"\n",
       "   (Meaning: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏π‡∏ï‡∏Ç‡∏≠‡∏á‡πÄ‡∏ò‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏£‡∏à‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏™‡∏±‡∏ô‡∏ï‡∏¥‡∏†‡∏≤‡∏û)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = (\n",
    "    \"Answer in 8 languages: English, German, French, Italian,\" \n",
    "    \"Portuguese, Hindi, Spanish, and Thai\"\n",
    ")\n",
    "ml_conv = Conversation(system_message)\n",
    "response = ml_conv.generate(\"3 advanced phrases\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bd3d8-c291-4edd-9b60-8a3faffc5100",
   "metadata": {},
   "source": [
    "## Chatbot App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dda1354e-b37b-491e-a7f5-c2bb397d14d5",
   "metadata": {
    "height": 523
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a Python script for a Gradio chatbot app that you can run within a Jupyter notebook:\n",
      "\n",
      "```python\n",
      "import gradio as gr\n",
      "\n",
      "# Initialize the conversation with a system message\n",
      "conversation = Conversation(system=\"You are an expert in literature. You provide brief replies.\")\n",
      "\n",
      "# Define a function to handle user input\n",
      "def chat(user_input, model_size, temperature):\n",
      "    # Generate a response using the Conversation class\n",
      "    response = conversation.generate(user_input, model=model_size, temp=temperature)\n",
      "    return response\n",
      "\n",
      "# Create a Gradio interface for the chatbot\n",
      "demo = gr.Interface(\n",
      "    fn=chat,\n",
      "    inputs=[\n",
      "        gr.Textbox(label=\"User Input\"),\n",
      "        gr.Radio(label=\"Model Size\", choices=[8, 70, 405], value=8),\n",
      "        gr.Slider(label=\"Temperature\", minimum=0, maximum=1, step=0.1, value=0)\n",
      "    ],\n",
      "    outputs=gr.Textbox(label=\"Assistant Response\"),\n",
      "    title=\"Literature Expert Chatbot\",\n",
      "    description=\"Ask me anything about literature!\"\n",
      ")\n",
      "\n",
      "# Launch the Gradio app\n",
      "demo.launch()\n",
      "```\n",
      "\n",
      "This script initializes the `Conversation` class with a system message, defines a function to handle user input, and creates a Gradio interface for the chatbot. The interface includes a text box for user input, radio buttons for selecting the model size, a slider for adjusting the temperature, and a text box for displaying the assistant's response. You can launch the Gradio app by running the `demo.launch()` method.\n",
      "\n",
      "Note that you'll need to have the `gradio` library installed in your Jupyter notebook environment. You can install it using pip: `!pip install gradio`. Also, make sure that the `llama31` function is defined and available in your notebook environment.\n"
     ]
    }
   ],
   "source": [
    "code_query = \"\"\"\n",
    "I need a Python script for a Gradio chatbot app that should be run\n",
    "within a Jupyter notebook.\n",
    "1) When calling the LLM, use this class, which is already defined,\n",
    "    dont redefine it:\n",
    "class Conversation:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def generate(self, user_question, model=8, temp=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_question})\n",
    "        response = llama31(self.messages, model, temperature=temp)  \n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "2) initialize the class with a system message of:\n",
    "    \"You are an expert in liturature. You provide brief replies\"\n",
    "3) the llama() function is defined like this:\n",
    "    def llama(prompt_or_messages, model_size=8, \n",
    "              temperature=0, raw=False, debug=False):\n",
    "    and returns a reponse in a string. Don't redefine this.\n",
    "    valid model sizes are 8, 70 and 405.\n",
    "\"\"\"\n",
    "coder_system_message = (\n",
    "    \"You are an expert writing python Gradio chatbots\" \n",
    ")\n",
    "coder_conv = Conversation(coder_system_message)\n",
    "response = coder_conv.generate(code_query, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43dd04e2-0986-41f7-9b44-21459445d3d8",
   "metadata": {
    "height": 659
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  https://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://s172-30-99-174p7860.lab-aws-production.deeplearning.ai/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the code generated by Llama in the video\n",
    "# Your response to the above prompt may differ - try running your response as well!\n",
    "# note, the final line was hand edited to add \"server_name=\"0.0.0.0\" to run in the course environment\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Initialize the conversation with a system message\n",
    "conversation = Conversation(\"You are an expert in literature. You provide brief replies.\")\n",
    "\n",
    "# Define a function to generate a response to the user's input\n",
    "def generate_response(user_input, model_size, temperature):\n",
    "    try:\n",
    "        model_size = int(model_size)\n",
    "        if model_size not in [8, 70, 405]:\n",
    "            return \"Invalid model size. Please choose from 8, 70, or 405.\"\n",
    "        temperature = float(temperature)\n",
    "        if temperature < 0 or temperature > 1:\n",
    "            return \"Invalid temperature. Please choose a value between 0 and 1.\"\n",
    "        response = conversation.generate(user_input, model=model_size, temp=temperature)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Create a Gradio interface for the chatbot\n",
    "demo = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"User Input\"),\n",
    "        gr.Radio(label=\"Model Size\", choices=[\"8\", \"70\", \"405\"]),\n",
    "        gr.Slider(label=\"Temperature\", minimum=0, maximum=1, step=0.1, value=0)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Response\"),\n",
    "    title=\"Literature Expert Chatbot\",\n",
    "    description=\"Ask a question about literature and get a brief response from an expert.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57bf3f4-63b5-45c7-943d-432e25376dd4",
   "metadata": {},
   "source": [
    "# A few more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79366c-678e-4f95-9bc7-520296fd9d54",
   "metadata": {
    "id": "Fz1IIJXajf77"
   },
   "source": [
    "## Compare with different sized Llama chat models\n",
    "\n",
    "By default, the llama31 call uses the Llama 3.1 8B Instruct model. To see how the 70B or 405B model responds, simply pass 70 or 405 after prompt. For example, let compare how the 3 different sized Llama 3.1 chat models respond to the question about a quote in Hemingway's classic The Old Man and the Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b420f914-9100-404d-bb66-22bc362774ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "f_WT9xQwaFbw",
    "outputId": "e40261ab-2c49-43fe-ec55-e1e5f658b26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The quote you're referring to is from Ernest Hemingway's novel \"The Old Man and the Sea\". The full quote is:\n",
      "\n",
      "\"Everything about him was old except his eyes and they were the same color as the sea and they seemed to hold the moon on their dark blue waters.\"\n",
      "\n",
      "This quote is from the first chapter of the novel, and it sets the tone for the rest of the story, which is a poignant and introspective exploration of the old man's life, his struggles, and his connection to the natural world.\n"
     ]
    }
   ],
   "source": [
    "question = \"The quote that starts with 'Everything about him is old' in The Old Man and the Sea\"\n",
    "\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019206b-dc6d-4a10-92d1-21b7dd30f528",
   "metadata": {
    "id": "OzlDWmD9koc9"
   },
   "source": [
    "If you like Hemingway, you know Llama 3.1 8B is hallucinating a bit, and \"old before they were young\"? Now try to see if 70B does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d73d605-872a-417a-ab06-4854670f2966",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "_pZ80oupaFeX",
    "outputId": "ea30acaf-8c39-49fb-b9ba-34cc1f08610b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The quote you're thinking of is:\n",
      "\n",
      "\"Everything about him was old except his eyes and they seemed to be the same color as the sea and were cheerful and undefeated.\"\n",
      "\n",
      "This is from the opening paragraph of Ernest Hemingway's novella \"The Old Man and the Sea\".\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5812ce-a099-47fc-b57b-e233c40e9498",
   "metadata": {
    "id": "Rnyukk3GlHAX"
   },
   "source": [
    "The response makes more sense, but definitely not Hemingway would've written. In fact, it'd hurt the eyes of his fans. Let's hope 405 will cure the pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ad1bace-7b20-429f-bb56-5b542c8a6567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "dIHVm7ralEo0",
    "outputId": "b72f8dc8-6142-46a2-f25c-73c6d5f168a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You're thinking of the famous quote from Ernest Hemingway's \"The Old Man and the Sea\"!\n",
      "\n",
      "The full quote is:\n",
      "\n",
      "\"Everything about him was old except his eyes and they were the same color as the sea and were cheerful and undefeated.\"\n",
      "\n",
      "Isn't that a beautiful and poignant description of the old man, Santiago?\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b25935-0914-485b-86dc-3d9f11398a98",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
