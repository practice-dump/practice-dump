{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-vision\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/7f/e10d602c2dc3f749f1b78377a3357790f1da71b28e7da9e5bc20b3a9bd40/google_cloud_vision-1.0.0-py2.py3-none-any.whl (435kB)\n",
      "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
      "  Downloading https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl (70kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.22.0)\n",
      "Collecting protobuf>=3.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/92/30/1b7ccde09bf0c535d11f18a574ed7d7572c729a8f754fd568b297be08b61/protobuf-3.11.3-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\n",
      "Collecting google-auth<2.0dev,>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl (76kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2019.3)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (42.0.2.post20191203)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.13.0)\n",
      "Collecting grpcio<2.0dev,>=1.8.2; extra == \"grpc\"\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/6d/99aba8db04bf58193ed157dfe7e848494b93dd8aa3f6a4d1edfef318779c/grpcio-1.27.2-cp37-cp37m-win_amd64.whl (1.9MB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\tanmey\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.25.7)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "Building wheels for collected packages: googleapis-common-protos\n",
      "  Building wheel for googleapis-common-protos (setup.py): started\n",
      "  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'\n",
      "  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.51.0-cp37-none-any.whl size=77603 sha256=d8b963c797f4a07d2a5ae6df3feb64723f4803427eb9187512c24aaeaa665811\n",
      "  Stored in directory: C:\\Users\\TANMEY\\AppData\\Local\\pip\\Cache\\wheels\\2c\\f9\\7f\\6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\n",
      "Successfully built googleapis-common-protos\n",
      "Installing collected packages: protobuf, googleapis-common-protos, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, grpcio, google-api-core, google-cloud-vision\n",
      "Successfully installed cachetools-4.0.0 google-api-core-1.16.0 google-auth-1.11.2 google-cloud-vision-1.0.0 googleapis-common-protos-1.51.0 grpcio-1.27.2 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When that’s taken care of, now you’ll need an instance of a client. \n",
    "\n",
    "To do so, you’re going to use a text recognition feature.\n",
    "\n",
    "If you won’t store your credentials in environment variables, at this stage you can add it directly to the client.\n",
    "\n",
    "By Credentials, I mean the Google Cloud API Key JSON file, you get to download it when you make a free account and want to activate one of the many Google Cloud APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient.from_service_account_file('My Project 77824-9ac23395f34c.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that you store images to be processed in a folder ‘images’ inside your project catalog, let’s open one of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_open = 'images/receipt.jpg'\n",
    "\n",
    "with open(image_to_open, 'rb') as image_file:\n",
    "    content = image_file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create a Vision object, which will allow you to send a request to proceed with text recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = vision.types.Image(content=content)\n",
    "\n",
    "text_response = client.text_detection(image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response consists of detected words stored as description keys, their location on the image, and a language prediction. For example, let’s take a closer look at the first word:\n",
    "\n",
    "But What did we actually upload?\n",
    "\n",
    "![title](images/receipt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, to filter text only, you need to get a description “on all the elements”. Luckily, with help comes Python’s powerful list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SHOPPING STORE\\nREG 12-21\\n03:22 PM\\nCLERK 2\\n618\\n1 MISC.\\n1 STUFF\\nSUBTOTAL\\n$0.49\\n$7.99\\n$8.48\\n$0.74\\n$9.22\\n$10.00\\n$0.78\\nTAX\\nTOTAL\\nCASH\\nCHANGE\\nNO REFUNDS\\nNO EXCHANGES\\nNO RETURNS\\n',\n",
       " 'SHOPPING',\n",
       " 'STORE',\n",
       " 'REG',\n",
       " '12-21',\n",
       " '03:22',\n",
       " 'PM',\n",
       " 'CLERK',\n",
       " '2',\n",
       " '618',\n",
       " '1',\n",
       " 'MISC.',\n",
       " '1',\n",
       " 'STUFF',\n",
       " 'SUBTOTAL',\n",
       " '$0.49',\n",
       " '$7.99',\n",
       " '$8.48',\n",
       " '$0.74',\n",
       " '$9.22',\n",
       " '$10.00',\n",
       " '$0.78',\n",
       " 'TAX',\n",
       " 'TOTAL',\n",
       " 'CASH',\n",
       " 'CHANGE',\n",
       " 'NO',\n",
       " 'REFUNDS',\n",
       " 'NO',\n",
       " 'EXCHANGES',\n",
       " 'NO',\n",
       " 'RETURNS']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [text.description for text in text_response.text_annotations]\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look carefully, you can notice that the first element of the list contains all text detected in the image stored as a string, while the others are separated words. \n",
    "\n",
    "Let’s print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOPPING STORE\n",
      "REG 12-21\n",
      "03:22 PM\n",
      "CLERK 2\n",
      "618\n",
      "1 MISC.\n",
      "1 STUFF\n",
      "SUBTOTAL\n",
      "$0.49\n",
      "$7.99\n",
      "$8.48\n",
      "$0.74\n",
      "$9.22\n",
      "$10.00\n",
      "$0.78\n",
      "TAX\n",
      "TOTAL\n",
      "CASH\n",
      "CHANGE\n",
      "NO REFUNDS\n",
      "NO EXCHANGES\n",
      "NO RETURNS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we’ve mentioned in this presentation above, Google Cloud Vision is not only about recognizing text, but also it lets you discover faces, landmarks, image properties, and web connections. \n",
    "\n",
    "With that in mind, let’s find out what it can tell you about web associations of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_response = client.web_detection(image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay Google, do you actually know what is shown on the image you received?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[label: \"receipt definition\"\n",
       "language_code: \"en\"\n",
       "]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_content = web_response.web_detection\n",
    "web_content.best_guess_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job, Google! It’s a receipt indeed. \n",
    "\n",
    "But let’s give you a bit more exercise — can you see anything else? \n",
    "\n",
    "How about more predictions expressed in percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Receipt', '88.39%'),\n",
       " ('Printer', '56.62%'),\n",
       " ('Payment', '45.57%'),\n",
       " ('Invoice', '42.03%'),\n",
       " ('Cash register', '36.72%'),\n",
       " ('Shopping', '35.46%'),\n",
       " ('Return receipt', '34.30%'),\n",
       " ('', '27.56%'),\n",
       " ('', '25.65%'),\n",
       " ('', '25.62%')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [(entity.description, '{:.2%}'.format(entity.score)) for entity in web_content.web_entities]\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Google has given us a lot of valuable insights, well done, my almighty friend! \n",
    "\n",
    "Can you also find out where the image comes from and whether it has any copies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[url: \"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7669b141-9ff9-47e6-b56b-2bb1ff6e0d72/receipt-example-processed-by-google-cloud-vision.png\"\n",
       ", url: \"https://www.collinsdictionary.com/images/thumb/receipt_573065707_250.jpg\"\n",
       ", url: \"https://media.gettyimages.com/photos/shopping-receipt-picture-id901964616?b=1&k=6&m=901964616&s=170x170&h=DVyqX2Q6sgDuMCQ7oVW4n4S4X5lGT7ylOEUQ-mL0Rg0=\"\n",
       ", url: \"https://thumbs.dreamstime.com/t/recibo-da-compra-85651861.jpg\"\n",
       "]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_content.full_matching_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I’m impressed. Thanks, Google! \n",
    "\n",
    "But one is not enough, can you please give me three or more examples of similar images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[url: \"https://images-na.ssl-images-amazon.com/images/I/51X5KPbHPOL._SX500_.jpg\",\n",
       " url: \"https://ctl.s6img.com/society6/img/m1gmW5rFvbVc8_cIby7hNYO3qTA/w_1500/bath-towels/small/front/~artwork,fw_7400,fh_3700,iw_7400,ih_3700/s6-original-art-uploads/society6/uploads/misc/916b12db7d714e649c4d6364d7eb3e14/~~/psychology-psychology-gifts-psychology-definition-funny-definition-funny-quotes-dictionary-art-bath-towels.jpg\",\n",
       " url: \"https://ctl.s6img.com/society6/img/l67X0bB5HCDHt7qYyJaY5HgSmvo/w_700/bath-towels/small/front/~artwork,fw_7400,fh_3700,iw_7400,ih_3700/s6-original-art-uploads/society6/uploads/misc/ca6190d488ee4975b40d7aae67242d9c/~~/laundry-definition-dictionary-word-laundry-print-instant-download-printable-quote-dictiona-bath-towels.jpg\",\n",
       " url: \"https://ctl.s6img.com/society6/img/kvtUAnUq3IIgs0tjClA4M371jXA/w_700/bath-towels/small/front/~artwork,fw_7400,fh_3700,iw_7400,ih_3700/s6-original-art-uploads/society6/uploads/misc/f8c09fca79d6419ca6977c36b572b3ce/~~/create-definition-create-quote-print-artist-gift-crafter-gift-craftsman-gift-office-wall-art-h-bath-towels.jpg\",\n",
       " url: \"https://ctl.s6img.com/society6/img/kBm2NtUAF8Rtxkh8_KkK2NiZ2to/w_1500/shams/standard/alternate/~artwork,fw_6105,fh_3504,fx_1752,fy_447,iw_2600,ih_2600/s6-original-art-uploads/society6/uploads/misc/9df45d65b665436a940a9f18f38ad496/~~/the-easy-breezy-definition-of-summer-shams.jpg\",\n",
       " url: \"https://ctl.s6img.com/society6/img/725xwax6UTPr28HQwni12fy6Z4g/w_700/bath-towels/small/front/~artwork,fw_3708,fh_7410,fx_-165,fy_1138,iw_4026,ih_5124/s6-original-art-uploads/society6/uploads/misc/169e7f1a700d40b4a32c564d810f9c5d/~~/floordrobe-bath-towels.jpg\",\n",
       " url: \"http://getdrawings.com/vectors/receipt-vector-4.jpg\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_content.visually_similar_images[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Similar Images found by Google Cloud are:\n",
    "\n",
    "![title](images/gcvpred2.jpg)\n",
    "\n",
    "![title](images/gcpred1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's Challenge ourselves\n",
    "\n",
    "Let's have a look at what the Google Cloud Vision API can tell us about this photo of our legendary Professor Venkatesh.\n",
    "\n",
    "![title](images/face.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "503 DNS resolution failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    825\u001b[0m                                       wait_for_ready, compression)\n\u001b[1;32m--> 826\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"DNS resolution failed\"\n\tdebug_error_string = \"{\"created\":\"@1583729850.703000000\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3941,\"referenced_errors\":[{\"created\":\"@1583729850.703000000\",\"description\":\"Resolver transient failure\",\"file\":\"src/core/ext/filters/client_channel/resolving_lb_policy.cc\",\"file_line\":262,\"referenced_errors\":[{\"created\":\"@1583729850.703000000\",\"description\":\"DNS resolution failed\",\"file\":\"src/core/ext/filters/client_channel/resolver/dns/native/dns_resolver.cc\",\"file_line\":202,\"grpc_status\":14,\"referenced_errors\":[{\"created\":\"@1583729850.703000000\",\"description\":\"OS Error\",\"file\":\"src/core/lib/iomgr/resolve_address_windows.cc\",\"file_line\":96,\"os_error\":\"No such host is known.\\r\\n\",\"syscall\":\"getaddrinfo\",\"wsa_error\":11001}]}]}]}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-48d4b9434cdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mface_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mface_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\vision_helpers\\decorators.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(self, image, max_results, retry, timeout, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mcopied_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_results\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcopied_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\vision_helpers\\__init__.py\u001b[0m in \u001b[0;36mannotate_image\u001b[1;34m(self, request, retry, timeout)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# of them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mprotobuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"features\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_all_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_annotate_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\vision_v1\\gapic\\image_annotator_client.py\u001b[0m in \u001b[0;36mbatch_annotate_images\u001b[1;34m(self, requests, parent, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         return self._inner_api_calls[\"batch_annotate_images\"](\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m         )\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: 503 DNS resolution failed"
     ]
    }
   ],
   "source": [
    "image_to_open = 'images/face.jpg'\n",
    "\n",
    "with open(image_to_open, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "image = vision.types.Image(content=content)\n",
    "\n",
    "face_response = client.face_detection(image=image)\n",
    "face_content = face_response.face_annotations\n",
    "\n",
    "face_content[0].detection_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, the algorithm is more than 71% sure that there is a face in the picture. \n",
    "\n",
    "But can we learn anything about the emotions behind it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bounding_poly {\n",
       "  vertices {\n",
       "    x: 357\n",
       "    y: 23\n",
       "  }\n",
       "  vertices {\n",
       "    x: 692\n",
       "    y: 23\n",
       "  }\n",
       "  vertices {\n",
       "    x: 692\n",
       "    y: 413\n",
       "  }\n",
       "  vertices {\n",
       "    x: 357\n",
       "    y: 413\n",
       "  }\n",
       "}\n",
       "fd_bounding_poly {\n",
       "  vertices {\n",
       "    x: 381\n",
       "    y: 99\n",
       "  }\n",
       "  vertices {\n",
       "    x: 666\n",
       "    y: 99\n",
       "  }\n",
       "  vertices {\n",
       "    x: 666\n",
       "    y: 379\n",
       "  }\n",
       "  vertices {\n",
       "    x: 381\n",
       "    y: 379\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EYE\n",
       "  position {\n",
       "    x: 477.2466735839844\n",
       "    y: 209.75875854492188\n",
       "    z: -0.000423431396484375\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EYE\n",
       "  position {\n",
       "    x: 576.2607421875\n",
       "    y: 214.8441162109375\n",
       "    z: -3.6672720909118652\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_OF_LEFT_EYEBROW\n",
       "  position {\n",
       "    x: 445.35150146484375\n",
       "    y: 187.74644470214844\n",
       "    z: 8.20673942565918\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_OF_LEFT_EYEBROW\n",
       "  position {\n",
       "    x: 503.37744140625\n",
       "    y: 189.62448120117188\n",
       "    z: -22.31841468811035\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_OF_RIGHT_EYEBROW\n",
       "  position {\n",
       "    x: 550.7940673828125\n",
       "    y: 192.64932250976562\n",
       "    z: -24.06309700012207\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_OF_RIGHT_EYEBROW\n",
       "  position {\n",
       "    x: 611.7736206054688\n",
       "    y: 195.72874450683594\n",
       "    z: 2.1026289463043213\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: MIDPOINT_BETWEEN_EYES\n",
       "  position {\n",
       "    x: 525.871337890625\n",
       "    y: 211.67601013183594\n",
       "    z: -23.044635772705078\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: NOSE_TIP\n",
       "  position {\n",
       "    x: 516.3055419921875\n",
       "    y: 276.552490234375\n",
       "    z: -48.20429229736328\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: UPPER_LIP\n",
       "  position {\n",
       "    x: 517.9017944335938\n",
       "    y: 312.0703125\n",
       "    z: -22.376197814941406\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LOWER_LIP\n",
       "  position {\n",
       "    x: 519.6436157226562\n",
       "    y: 346.0128173828125\n",
       "    z: -12.788161277770996\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: MOUTH_LEFT\n",
       "  position {\n",
       "    x: 477.13623046875\n",
       "    y: 325.77117919921875\n",
       "    z: 6.912448883056641\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: MOUTH_RIGHT\n",
       "  position {\n",
       "    x: 562.2606201171875\n",
       "    y: 329.621826171875\n",
       "    z: 3.979644775390625\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: MOUTH_CENTER\n",
       "  position {\n",
       "    x: 517.2210693359375\n",
       "    y: 326.0855712890625\n",
       "    z: -13.748438835144043\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: NOSE_BOTTOM_RIGHT\n",
       "  position {\n",
       "    x: 549.926025390625\n",
       "    y: 286.6688232421875\n",
       "    z: -11.251811027526855\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: NOSE_BOTTOM_LEFT\n",
       "  position {\n",
       "    x: 492.9029541015625\n",
       "    y: 283.0429992675781\n",
       "    z: -9.140161514282227\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: NOSE_BOTTOM_CENTER\n",
       "  position {\n",
       "    x: 519.064208984375\n",
       "    y: 294.1029968261719\n",
       "    z: -24.37298011779785\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EYE_TOP_BOUNDARY\n",
       "  position {\n",
       "    x: 476.3424987792969\n",
       "    y: 199.65089416503906\n",
       "    z: -6.517873764038086\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EYE_RIGHT_CORNER\n",
       "  position {\n",
       "    x: 498.98040771484375\n",
       "    y: 213.31459045410156\n",
       "    z: -0.7733936309814453\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EYE_BOTTOM_BOUNDARY\n",
       "  position {\n",
       "    x: 475.71563720703125\n",
       "    y: 218.03915405273438\n",
       "    z: -0.43805503845214844\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EYE_LEFT_CORNER\n",
       "  position {\n",
       "    x: 456.3703308105469\n",
       "    y: 210.19375610351562\n",
       "    z: 9.966094017028809\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EYE_TOP_BOUNDARY\n",
       "  position {\n",
       "    x: 579.1569213867188\n",
       "    y: 205.74411010742188\n",
       "    z: -10.301529884338379\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EYE_RIGHT_CORNER\n",
       "  position {\n",
       "    x: 595.75\n",
       "    y: 216.88345336914062\n",
       "    z: 4.82460880279541\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EYE_BOTTOM_BOUNDARY\n",
       "  position {\n",
       "    x: 577.323486328125\n",
       "    y: 223.27978515625\n",
       "    z: -4.254854202270508\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EYE_LEFT_CORNER\n",
       "  position {\n",
       "    x: 555.1207275390625\n",
       "    y: 216.22366333007812\n",
       "    z: -2.8918352127075195\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EYEBROW_UPPER_MIDPOINT\n",
       "  position {\n",
       "    x: 474.4151916503906\n",
       "    y: 179.12301635742188\n",
       "    z: -14.127214431762695\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EYEBROW_UPPER_MIDPOINT\n",
       "  position {\n",
       "    x: 582.34619140625\n",
       "    y: 184.46307373046875\n",
       "    z: -18.018497467041016\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: LEFT_EAR_TRAGION\n",
       "  position {\n",
       "    x: 417.49822998046875\n",
       "    y: 239.0426025390625\n",
       "    z: 131.0580291748047\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: RIGHT_EAR_TRAGION\n",
       "  position {\n",
       "    x: 631.1659545898438\n",
       "    y: 245.688232421875\n",
       "    z: 123.92367553710938\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: FOREHEAD_GLABELLA\n",
       "  position {\n",
       "    x: 526.55419921875\n",
       "    y: 191.10992431640625\n",
       "    z: -26.74704360961914\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: CHIN_GNATHION\n",
       "  position {\n",
       "    x: 518.6713256835938\n",
       "    y: 394.797607421875\n",
       "    z: 5.272212982177734\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: CHIN_LEFT_GONION\n",
       "  position {\n",
       "    x: 430.9580993652344\n",
       "    y: 326.51751708984375\n",
       "    z: 95.0251693725586\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  type: CHIN_RIGHT_GONION\n",
       "  position {\n",
       "    x: 605.6546020507812\n",
       "    y: 333.50103759765625\n",
       "    z: 88.8559799194336\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  position {\n",
       "    x: 453.0548400878906\n",
       "    y: 279.0414733886719\n",
       "    z: 15.139933586120605\n",
       "  }\n",
       "}\n",
       "landmarks {\n",
       "  position {\n",
       "    x: 590.0958862304688\n",
       "    y: 285.548583984375\n",
       "    z: 10.146903038024902\n",
       "  }\n",
       "}\n",
       "roll_angle: 3.3203775882720947\n",
       "pan_angle: -2.0412211418151855\n",
       "tilt_angle: -5.119505405426025\n",
       "detection_confidence: 0.8561579585075378\n",
       "landmarking_confidence: 0.7266718745231628\n",
       "joy_likelihood: VERY_UNLIKELY\n",
       "sorrow_likelihood: VERY_UNLIKELY\n",
       "anger_likelihood: VERY_UNLIKELY\n",
       "surprise_likelihood: VERY_UNLIKELY\n",
       "under_exposed_likelihood: VERY_UNLIKELY\n",
       "blurred_likelihood: VERY_UNLIKELY\n",
       "headwear_likelihood: VERY_UNLIKELY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scope of possibilities to apply Google Cloud Vision service is practically endless. With Python Library available, you can utilize it in any project based on the language, whether it’s a web application or a scientific project. It can certainly help you bring out deeper interest in Machine Learning technologies.\n",
    "\n",
    "Google documentation provides some great ideas on how to apply the Vision API features in practice as well as gives you the possibility to learn more about the Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
